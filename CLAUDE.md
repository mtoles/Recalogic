# Logial Operators in First Stage Recall

The objective of this project is to benchmark and train a model to do accurate first-stage recall on products when queries contain multiple logical operators (and, or, not)

# Spec

We will be using the ESCI product dataset

https://huggingface.co/datasets/tasksource/esci

The dataset contains the following columns:

example_id (int64), query (string), query_id (int64), product_id (string), product_locale (string), esci_label (string), small_version (int64), large_version (int64), product_title (string), product_description (string), product_bullet_point (string), product_brand (string), product_color (string), product_text (string)

Our project will consist of the following main steps:

# Dataset

We aim to create a dataset consisting of examples in the following format:

- Query, q:                      "Black shirt without logo and without text"
- Positive Product, p_p:         "This black shirt doesn't have any logo or text on it so you will look stylish"
- Hard Negative Product, p_h:    "This white shirt doesn't have any logo or text on it so you will look stylish"
- Easy Negative Product, p_e:    "This pickup truck is black and awesome"
- Distance, d:                   Int, the minimum number of feature edits necessary to make p_h satisfy q

Features are defined not by ESCI but synthesized with a LLM.
For example, features in the above p_p and p_h would be black, white, has_logo, has_text.
Shirt and truck are not a features but rather a categories.
There will be one hard and one easy negative per positive.
Easy negatives are chosen at random from the dataset.

1. Feature Extraction

The column esci_label contains four categories: Exact, Substitute, Irrelevant, and Complement.
We ignore Complement entirely.
The majority of examples are Exact, so we use both Substitue and Irrelevant to construct hard negatives.
We first prompt the LLM to identify between 1 and N_FEATURES=4 features by which the Exact and Substitute/Irrelevant for a given query differ.
We then use the LLM to determine for the Exact and Sub/Irr products whether the feature applies to them.
We store this data in the example dict.
Some queries contain one or more features (e.g. "shirt" (0 features) vs. "white shirt" (1 feature)). 
If the query contains 1+ features, we include those as features, reducing the number of features generated by that many.

2. Query Generation

We wish to generate a "query function" in boolean SAT style logical form, irrespective of the actual features. 
The query function is a function that takes booleans f_1...f_n and returns a boolean value.
We generate one randomly, i.e.
(f_4 and f_2) and (not f_3 or f_1)
Each feature should appear exactly once in the query function.
Shuffle feature order.
Then randomly generate queries according to a grammar.
The grammar should allow:
  - f_1...f_n used only once
  - Paretheses must be closed by the end
  - And, Or, Not, ()
We create a natural language description of the query function.
For the features "white", "large", "cotton", "Nike", we could have "white, large sweater that is not size large or is from Nike"


3. Calculate Edit Distance

d:=dist(q, p) is the minimum number of features that would need to be changed for product p to satisfy query q.
Calculate this using brute force or some better method

4. Finalization

Save the dataset in a jsonl file

5. Proof

Generate a report showing summary statistics and several examples 


# Training

Do not do this yet

# Technologies

Use GPT-5 via OpenAI API for inference.
Connect to it via OpenAI Python client
Use venv

# Features

- The ability to process only n examples from the dataset, for testing
- Train/test split as a column in the db
- Use logging
- Parallelize OpenAI API calls
- Keep the repo clean


# Development Guidelines

Never add dummy code.
After each time you make a substantial new edit, do:
1. Run the code to check that it works (its ok if it crashes on features we haven't discussed yet)
2. If it doesn't work, try to fix it 
3. Once you have fixed it, provide proof that it is fixed, such as a summary of results